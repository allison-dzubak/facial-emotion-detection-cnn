{"cells":[{"cell_type":"markdown","source":["This notebook contains the first step of data preprocessing for the MIT ADSP capstone project on facial emotion detection\n","\n","Performed here:\n","- Use a facial detection model to detect if a face is present in the image\n","- Store images where a face was detected for subsequent preprocessing data cleaning"],"metadata":{"id":"TIPdwXKVHIHh"}},{"cell_type":"markdown","metadata":{"id":"b_9LnbnEDfdr"},"source":["Google Colab setup"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SSAJUh9uDimC"},"outputs":[],"source":["# Mount the drive\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","# Set main directory\n","main_directory = '/content/drive/MyDrive/facial-emotion-detection-cnn'"]},{"cell_type":"markdown","metadata":{"id":"GJC3R9sdDl-O"},"source":["Get some helpful tools"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tU8xOTpODoMB"},"outputs":[],"source":["# Get face detection model to clean dataset (to remove non-faces before training)\n","!wget -N https://raw.githubusercontent.com/opencv/opencv/master/samples/dnn/face_detector/deploy.prototxt\n","!wget -N https://raw.githubusercontent.com/opencv/opencv_3rdparty/dnn_samples_face_detector_20170830/res10_300x300_ssd_iter_140000.caffemodel"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dfXvUv1LDunh"},"outputs":[],"source":["# Import the libraries\n","import os\n","from pathlib import Path\n","import imutils\n","import glob\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from google.colab.patches import cv2_imshow"]},{"cell_type":"markdown","source":["Access 'common_functions.py' file"],"metadata":{"id":"cKW1xugtekci"}},{"cell_type":"code","source":["# Specify path to common functions python file\n","project_path = Path(os.path.join(main_directory, 'notebooks'))\n","common_functions_file = 'common_functions.py'\n","\n","# Construct the full path of common functions python file\n","full_path = project_path / common_functions_file\n","\n","# Use exec to run the file\n","exec(open(full_path).read())"],"metadata":{"id":"RzVGakV2dssD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Specify location of preprocessed data after face detection. High confidence images are likely to have a face, low conficence images are not likely to have a face."],"metadata":{"id":"w5C0Iptn95Mh"}},{"cell_type":"code","source":["# Set original data directory\n","original_data_directory = os.path.join(main_directory, 'data/Facial_emotion_images')\n","\n","# Specify directories where the high confidence and low confidence images will be stored\n","high_confidence_directory = os.path.join(main_directory, 'data/face_detection/high_confidence_images')\n","low_confidence_directory = os.path.join(main_directory, 'data/face_detection/low_confidence_images')\n","\n","# Create the directories if they do not exist\n","os.makedirs(high_confidence_directory, exist_ok=True)\n","os.makedirs(low_confidence_directory, exist_ok=True)"],"metadata":{"id":"KzZuGndP-ATQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VKKivHoiWI5-"},"source":["There are some images that are labeled but did not have faces. To clean the data, detect if the image has a face using a face detection model.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"DIS4oez5ifRw"},"source":["A random subset of training and validation images was selected that contained an image without a face to test the face detection model. The subset of images is listed below and stored in a list as 'image_set_for_face_detection'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R4V9LfT7hxZs"},"outputs":[],"source":["# Printout of image subset\n","printout = \"\"\"\n","train/happy/26878.jpg\n","train/happy/34954.jpg\n","train/happy/27141.jpg\n","train/happy/20268.jpg\n","train/happy/17747.jpg\n","train/happy/24275.jpg\n","train/happy/26709.jpg\n","train/happy/26314.jpg\n","train/happy/20021.jpg\n","train/happy/20226.jpg\n","train/happy/21749.jpg\n","train/happy/27422.jpg\n","validation/happy/33228.jpg\n","validation/happy/3755.jpg\n","validation/happy/35481.jpg\n","validation/happy/12497.jpg\n","validation/happy/31908.jpg\n","validation/happy/23238.jpg\n","validation/happy/33216.jpg\n","validation/happy/28367.jpg\n","validation/happy/18226.jpg\n","validation/happy/20365.jpg\n","validation/happy/16308.jpg\n","validation/happy/35552.jpg\n","train/sad/12700.jpg\n","train/sad/24999.jpg\n","train/sad/10334.jpg\n","train/sad/27168.jpg\n","train/sad/10407.jpg\n","train/sad/28978.jpg\n","train/sad/32221.jpg\n","train/sad/11886.jpg\n","train/sad/31217.jpg\n","train/sad/11380.jpg\n","train/sad/21983.jpg\n","train/sad/18186.jpg\n","validation/sad/29243.jpg\n","validation/sad/33747.jpg\n","validation/sad/5061.jpg\n","validation/sad/23948.jpg\n","validation/sad/29970.jpg\n","validation/sad/28073.jpg\n","validation/sad/26612.jpg\n","validation/sad/32613.jpg\n","validation/sad/14048.jpg\n","validation/sad/1148.jpg\n","validation/sad/10339.jpg\n","validation/sad/30035.jpg\n","train/surprise/11257.jpg\n","train/surprise/12685.jpg\n","train/surprise/13090.jpg\n","train/surprise/1464.jpg\n","train/surprise/22583.jpg\n","train/surprise/6655.jpg\n","train/surprise/5616.jpg\n","train/surprise/8229.jpg\n","train/surprise/28986.jpg\n","train/surprise/11556.jpg\n","train/surprise/8975.jpg\n","train/surprise/13173.jpg\n","validation/surprise/4390.jpg\n","validation/surprise/25390.jpg\n","validation/surprise/11414.jpg\n","validation/surprise/18521.jpg\n","validation/surprise/21906.jpg\n","validation/surprise/23053.jpg\n","validation/surprise/24893.jpg\n","validation/surprise/27774.jpg\n","validation/surprise/13009.jpg\n","validation/surprise/25571.jpg\n","validation/surprise/16959.jpg\n","validation/surprise/30714.jpg\n","train/neutral/34311.jpg\n","train/neutral/26548.jpg\n","train/neutral/11203.jpg\n","train/neutral/8752.jpg\n","train/neutral/35819.jpg\n","train/neutral/32786.jpg\n","train/neutral/22735.jpg\n","train/neutral/11003.jpg\n","train/neutral/15144.jpg\n","train/neutral/16416.jpg\n","train/neutral/8854.jpg\n","train/neutral/29915.jpg\n","validation/neutral/25507.jpg\n","validation/neutral/20875.jpg\n","validation/neutral/33526.jpg\n","validation/neutral/26647.jpg\n","validation/neutral/16714.jpg\n","validation/neutral/4449.jpg\n","validation/neutral/23741.jpg\n","validation/neutral/28478.jpg\n","validation/neutral/33794.jpg\n","validation/neutral/14187.jpg\n","validation/neutral/8247.jpg\n","validation/neutral/28782.jpg\n","\"\"\"\n","\n","# Split the printout into lines and store them in a list\n","image_set_for_face_detection = printout.strip().split('\\n')\n","\n","# Specify image paths relative to main directory\n","image_paths_for_face_detection = [os.path.join(original_data_directory, path) for path in image_set_for_face_detection]"]},{"cell_type":"markdown","metadata":{"id":"clbqKbe5bYKJ"},"source":["Visualize how the face detection model works"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"skkNz7PFc_iF"},"outputs":[],"source":["# Load the face detection model\n","prototxt = 'deploy.prototxt'\n","model = 'res10_300x300_ssd_iter_140000.caffemodel'\n","net = cv2.dnn.readNetFromCaffe(prototxt, model)\n","\n","# Function to display images in rows with specified number of images per row\n","def display_images_in_rows(images, images_per_row=6):\n","    num_images = len(images)\n","    images_per_row = min(num_images, images_per_row)\n","    num_rows = (num_images - 1) // images_per_row + 1\n","\n","    for i in range(num_rows):\n","        start_idx = i * images_per_row\n","        end_idx = min(start_idx + images_per_row, num_images)\n","        row_images = images[start_idx:end_idx]\n","\n","        row_concatenated = np.concatenate(row_images, axis=1)\n","        cv2_imshow(row_concatenated)\n","\n","# List to store processed images\n","processed_images = []\n","\n","# Loop through all images in the list\n","for image_path in image_paths_for_face_detection:\n","    # Read the image\n","    image = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n","\n","    # Convert the image to color (if it's grayscale)\n","    if len(image.shape) == 2:\n","        image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n","\n","    # Resize the image to have a maximum width of 400 pixels\n","    image = imutils.resize(image, width=400)\n","    (h, w) = image.shape[:2]\n","\n","    # Prepare the input blob for the neural network\n","    blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n","\n","    # Perform face detection\n","    net.setInput(blob)\n","    detections = net.forward()\n","\n","    # Loop over the detections\n","    for i in range(0, detections.shape[2]):\n","        confidence = detections[0, 0, i, 2]\n","\n","        # Filter out weak detections by ensuring the confidence is greater than the minimum confidence threshold\n","        if confidence > 0.5:\n","            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n","            (startX, startY, endX, endY) = box.astype(\"int\")\n","            text = \"{:.2f}%\".format(confidence * 100)\n","            y = startY - 10 if startY - 10 > 10 else startY + 10\n","            cv2.rectangle(image, (startX, startY), (endX, endY), (0, 0, 255), 2)\n","            cv2.putText(image, text, (startX, y), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)\n","\n","    # Store the processed image\n","    processed_images.append(image)\n","\n","# Display the processed images in rows\n","display_images_in_rows(processed_images, images_per_row=6)"]},{"cell_type":"markdown","metadata":{"id":"9Ca0I9ztgIRA"},"source":["**Observations:** The face detection model seems to do a good job at identifying faces from all emotion classes even with the presence of watermarks and occlusions. It finds faces with high confidence in all cases, except for the case where there is no face in the image."]},{"cell_type":"markdown","metadata":{"id":"N3vJYL3jenww"},"source":["Now scan the entire original dataset to find all images where we are not confident that a face is present. High confidence images are likely to have a face, low conficence images are not likely to have a face.\n","\n","WARNING: Slow time bottleneck. Store face detection results in designated directory for preprocessed data with the same directory structure as the original dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K_l5jhxpDzsC"},"outputs":[],"source":["# Load the face detection model\n","prototxt = 'deploy.prototxt'\n","model = 'res10_300x300_ssd_iter_140000.caffemodel'\n","net = cv2.dnn.readNetFromCaffe(prototxt, model)\n","\n","# Directories to traverse within base directory\n","directories = ['train', 'validation', 'test']\n","\n","# Emotion categories to traverse within directories\n","emotions = ['happy', 'sad', 'neutral', 'surprise']\n","\n","# Loop through all directories and subdirectories\n","for directory in directories:\n","    for emotion in emotions:\n","        # Directory containing images\n","        current_directory = os.path.join(original_data_directory, directory, emotion)\n","\n","        # Create the corresponding directory structure in the output directory\n","        output_subdirectory_low = os.path.join(low_confidence_directory, directory, emotion)\n","        output_subdirectory_high = os.path.join(high_confidence_directory, directory, emotion)\n","        os.makedirs(output_subdirectory_low, exist_ok=True)\n","        os.makedirs(output_subdirectory_high, exist_ok=True)\n","\n","        # Loop through all images in the current directory\n","        for filename in os.listdir(current_directory):\n","            if filename.endswith((\".jpg\", \".png\")):\n","                # Read the image\n","                image_path = os.path.join(current_directory, filename)\n","                image = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n","\n","                # Convert the image to color (if it's grayscale)\n","                if len(image.shape) == 2:\n","                    image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n","\n","                # Resize the image to have a maximum width of 400 pixels\n","                image = imutils.resize(image, width=400)\n","                (h, w) = image.shape[:2]\n","\n","                # Prepare the input blob for the neural network\n","                blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n","\n","                # Perform face detection\n","                net.setInput(blob)\n","                detections = net.forward()\n","\n","                # Flag to check if high confidence face detection is found\n","                high_confidence_detected = False\n","\n","                # Loop over the detections\n","                for i in range(0, detections.shape[2]):\n","                    confidence = detections[0, 0, i, 2]\n","\n","                    # Check if confidence is high\n","                    if confidence > 0.5:\n","                        high_confidence_detected = True\n","\n","                # If high confidence detection found, save the image to high confidence directory\n","                if high_confidence_detected:\n","                    output_path = os.path.join(output_subdirectory_high, filename)\n","                    cv2.imwrite(output_path, image)\n","                # If no high confidence detection found, save the image to low confidence directory\n","                else:\n","                    output_path = os.path.join(output_subdirectory_low, filename)\n","                    cv2.imwrite(output_path, image)"]},{"cell_type":"markdown","metadata":{"id":"7mDd_KfDFoyJ"},"source":["Count and visualize the distribution of images found that did not detect a face"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2aebDI0qDz1o"},"outputs":[],"source":["# Define the list of subdirectories\n","subdirectories = ['train', 'validation', 'test']\n","emotions = ['happy', 'sad', 'surprise', 'neutral']\n","\n","# Initialize lists to store counts\n","low_counts = []\n","high_counts = []\n","\n","# Function to count the number of images in a directory\n","def count_images(directory):\n","    count = 0\n","    for filename in os.listdir(directory):\n","        if filename.endswith((\".jpg\", \".png\")):\n","            count += 1\n","    return count\n","\n","# Loop through each directory and count the number of images\n","for subdirectory in subdirectories:\n","    for emotion in emotions:\n","        # Low Confidence Images\n","        directory_low = os.path.join(low_confidence_directory, subdirectory, emotion)\n","        count_low = count_images(directory_low)\n","        low_counts.append(count_low)\n","\n","        # High Confidence Images\n","        directory_high = os.path.join(high_confidence_directory, subdirectory, emotion)\n","        count_high = count_images(directory_high)\n","        high_counts.append(count_high)\n","\n","# Calculate the ratio of low to high confidence images\n","ratios = [low / (low + high) for low, high in zip(low_counts, high_counts)]\n","\n","# Plotting the bar chart\n","fig, ax = plt.subplots(figsize=(10, 6))\n","x = range(len(subdirectories) * len(emotions))\n","bar_width = 0.35\n","\n","# Plotting bars for low confidence images\n","bars_low = ax.bar(x, low_counts, bar_width, label='Low Confidence', color='b')\n","\n","# Plotting bars for high confidence images\n","bars_high = ax.bar([i + bar_width for i in x], high_counts, bar_width, label='High Confidence', color='r')\n","\n","# Adding labels and title\n","ax.set_xlabel('Directories/Emotions')\n","ax.set_ylabel('Number of Images')\n","ax.set_title('Number of Low and High Confidence Images by Directories/Emotions')\n","ax.set_xticks([i + bar_width / 2 for i in x])\n","ax.set_xticklabels([f\"{subdir}/{emotion}\" for subdir in subdirectories for emotion in emotions], rotation=45)\n","ax.legend()\n","\n","# Adding text annotations for the ratio\n","for i, ratio in enumerate(ratios):\n","    ax.text(i, max(low_counts[i], high_counts[i]), f'{ratio:.2f}', ha='center', va='bottom')\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"9VQ1718lGIsZ"},"source":["**Observations:** Overall, the percentage of images where a face was not detected are small. There tend to be more 'low confidence' images in the 'sad' emotion class. Proceed with data cleaning on the 'high confidence' images where a face was detected.\n","\n","Note: There are images in the test dataset where a face was not detected. Document carefully during the final model testing stage."]},{"cell_type":"markdown","metadata":{"id":"5sJCYf8UGSLw"},"source":["Show distribution of the 'high confidence' dataset (where non-face images are excluded)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uZ9jwVciGebU"},"outputs":[],"source":["# Print number of files within the high-confidence image directory\n","print_number_of_files(high_confidence_directory)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qN1Z9-IwO44x"},"outputs":[],"source":["# Show distribution of data in train, validation, and test set\n","show_pie_charts(high_confidence_directory)"]},{"cell_type":"markdown","metadata":{"id":"lQizm821mYPq"},"source":["**Observations:** The overall distribution of the data has not changed significantly from this data cleaning step. Proceed with the 'high confidence' images to the next cleaning step."]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":0}