{"cells":[{"cell_type":"markdown","source":["This notebook contains visualizations of the data augmentations used for the MIT ADSP capstone project on facial emotion detection."],"metadata":{"id":"E1i3JMJ5KM_z"}},{"cell_type":"markdown","metadata":{"id":"b_9LnbnEDfdr"},"source":["Google Colab setup"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SSAJUh9uDimC"},"outputs":[],"source":["# Mount the drive\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","# Set main directory\n","main_directory = '/content/drive/MyDrive/facial-emotion-detection-cnn'"]},{"cell_type":"markdown","metadata":{"id":"GJC3R9sdDl-O"},"source":["Get some helpful tools"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dfXvUv1LDunh"},"outputs":[],"source":["# Import the libraries\n","import os\n","import random\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from skimage import exposure\n","from matplotlib.image import imread\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator"]},{"cell_type":"markdown","source":["Access 'common_functions.py' file"],"metadata":{"id":"cKW1xugtekci"}},{"cell_type":"code","source":["# Specify path to common functions python file\n","project_path = Path(os.path.join(main_directory, 'notebooks'))\n","common_functions_file = 'common_functions.py'\n","\n","# Construct the full path of common functions python file\n","full_path = project_path / common_functions_file\n","\n","# Use exec to run the file\n","exec(open(full_path).read())"],"metadata":{"id":"RzVGakV2dssD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H-xQrxtKDrjK"},"source":["Specify location of preprocessed dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ymYB4Iz6Dyaz"},"outputs":[],"source":["# Specify path to preprocessed dataset\n","preprocessed_data_directory = os.path.join(main_directory, 'data/unique_images')"]},{"cell_type":"markdown","source":["Visualize the data augmentations"],"metadata":{"id":"5TvL5kpbM4We"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"m_9QkapWs_3o"},"outputs":[],"source":["# Define the list of emotion classes\n","emotion_classes = ['happy', 'sad', 'neutral', 'surprise']\n","\n","# Define the maximum range for each augmentation parameter\n","max_rotation_range = 15   # Maximum rotation angle (degrees)\n","max_shift_range = 0.05     # Maximum shift range (fraction of total width/height)\n","max_zoom_range = 0.05      # Maximum zoom range\n","\n","# Initialize ImageDataGenerator with desired augmentation parameters\n","train_datagen = ImageDataGenerator(rescale=1./255.,\n","                                   rotation_range=max_rotation_range,\n","                                   width_shift_range=max_shift_range,\n","                                   height_shift_range=max_shift_range,\n","                                   zoom_range=max_zoom_range,\n","                                   preprocessing_function=adjust_contrast_and_gamma,\n","                                   horizontal_flip=True)\n","\n","# Target size for resizing\n","target_size = (224, 224)\n","\n","# Initialize subplot grid\n","num_rows = len(emotion_classes)\n","num_cols = 7  # One column for each augmentation parameter\n","\n","fig, axs = plt.subplots(num_rows, num_cols, figsize=(15, 3*num_rows))\n","\n","# Iterate over each emotion class\n","for i, emotion in enumerate(emotion_classes):\n","    # Get a random image from the emotion class directory\n","    image_path = os.path.join(preprocessed_data_directory, 'train', emotion, np.random.choice(os.listdir(os.path.join(preprocessed_data_directory, 'train', emotion))))\n","    print(f\"Loading image: {image_path}\")\n","\n","    # Load the image\n","    img = imread(image_path)\n","\n","    # Display the original image\n","    axs[i, 0].imshow(img)\n","    axs[i, 0].set_title('Original')\n","    axs[i, 0].axis('off')\n","\n","    # Apply augmentation with the maximum range and display the augmented versions\n","    augmented_images = [img]  # List to store augmented images\n","\n","    # Rotation\n","    augmented_img = train_datagen.apply_transform(img, {'theta': max_rotation_range})\n","    axs[i, 1].imshow(augmented_img)\n","    axs[i, 1].set_title('Rotation')\n","    axs[i, 1].axis('off')\n","\n","    # Horizontal flip\n","    augmented_img = train_datagen.apply_transform(img, {'flip_horizontal': True})\n","    axs[i, 2].imshow(augmented_img)\n","    axs[i, 2].set_title('Horizontal Flip')\n","    axs[i, 2].axis('off')\n","\n","    # Width shift\n","    augmented_img = train_datagen.apply_transform(img, {'tx': max_shift_range * img.shape[1]})\n","    axs[i, 3].imshow(augmented_img)\n","    axs[i, 3].set_title('Width Shift')\n","    axs[i, 3].axis('off')\n","\n","    # Height shift\n","    augmented_img = train_datagen.apply_transform(img, {'ty': max_shift_range * img.shape[0]})\n","    axs[i, 4].imshow(augmented_img)\n","    axs[i, 4].set_title('Height Shift')\n","    axs[i, 4].axis('off')\n","\n","    # Zoom\n","    augmented_img = train_datagen.apply_transform(img, {'zx': 1 + max_zoom_range, 'zy': 1 + max_zoom_range})\n","    axs[i, 5].imshow(augmented_img)\n","    axs[i, 5].set_title('Zoom')\n","    axs[i, 5].axis('off')\n","\n","    # Adjust contrast/gamma\n","    augmented_img_contrast = adjust_contrast_and_gamma(img)\n","    axs[i, 6].imshow(augmented_img_contrast)\n","    axs[i, 6].set_title('Contrast')\n","    axs[i, 6].axis('off')\n","\n","plt.tight_layout()\n","plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":0}