{"cells":[{"cell_type":"markdown","source":["This notebook contains exploratory data analysis for the MIT ADSP capstone project on facial emotion detection.\n","\n","Performed here:\n","- Explore the dataset size and distribution of images by class\n","- Visualize a random sampling of dataset images"],"metadata":{"id":"TIPdwXKVHIHh"}},{"cell_type":"markdown","metadata":{"id":"b_9LnbnEDfdr"},"source":["Google Colab setup"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SSAJUh9uDimC"},"outputs":[],"source":["# Mount the drive\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","# Set main directory\n","main_directory = '/content/drive/MyDrive/facial-emotion-detection-cnn'"]},{"cell_type":"markdown","metadata":{"id":"GJC3R9sdDl-O"},"source":["Get some helpful tools"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dfXvUv1LDunh"},"outputs":[],"source":["# Import the libraries\n","import os\n","from pathlib import Path\n","import zipfile\n","import glob\n","import random\n","import base64\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from IPython.display import display, HTML"]},{"cell_type":"markdown","source":["Access 'common_functions.py' file"],"metadata":{"id":"cKW1xugtekci"}},{"cell_type":"code","source":["# Specify path to common functions python file\n","project_path = Path(os.path.join(main_directory, 'notebooks'))\n","common_functions_file = 'common_functions.py'\n","\n","# Construct the full path of common functions python file\n","full_path = project_path / common_functions_file\n","\n","# Use exec to run the file\n","exec(open(full_path).read())"],"metadata":{"id":"RzVGakV2dssD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XWQONn7hvyv4"},"source":["The MIT ADSP program office has provided a dataset of facial images pre-sorted by their associated emotions: happy, sad, surprise, and neutral. These have been divided into training, validation, and test subsets."]},{"cell_type":"markdown","metadata":{"id":"y3zSjYMBEWG5"},"source":["Load and unzip the original data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0oKEHnPyEYwZ"},"outputs":[],"source":["# Specify path to zipfile\n","zip_file_path = os.path.join(main_directory, 'data/Facial_emotion_images.zip')\n","\n","# Specify directory to extract to\n","extract_to_directory = os.path.join(main_directory, 'data/')\n","\n","# Create the directory if it does not exist\n","os.makedirs(extract_to_directory, exist_ok=True)\n","\n","# # Unzip the file\n","with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n","    zip_ref.extractall(extract_to_directory)"]},{"cell_type":"markdown","metadata":{"id":"Po7ej1e2EcFe"},"source":["Explore the size of the original dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Z9DiP7BEa5-"},"outputs":[],"source":["# Set original data directory\n","original_data_directory = os.path.join(main_directory, 'data/Facial_emotion_images')\n","\n","# Print number of files within the original data directory\n","print_number_of_files(original_data_directory)"]},{"cell_type":"markdown","metadata":{"id":"0ZuuygcBEgyO"},"source":["Visualize distribution of dataset and classes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"796hLInpEj8F"},"outputs":[],"source":["# Show distribution of data in train, validation, and test set\n","show_pie_charts(original_data_directory)"]},{"cell_type":"markdown","metadata":{"id":"yvy8ALMfEneU"},"source":["**Observations:** The ~20K images are divided into training, validation, and tests in the ratio above. The training and validation sets have less representation of the 'surprise' class. The Validation set has much more 'happy' representation' than any other class."]},{"cell_type":"markdown","metadata":{"id":"Yz4VSmK_EtPc"},"source":["Visualize a random sampling from the provided dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c1o9w2INEw1T"},"outputs":[],"source":["# Function to randomly select and display images\n","def display_random_images(emotion, dataset):\n","    # Get a random sample of 12 image files from each emotion class from each dataset\n","    emotion_dir = os.path.join(original_data_directory, dataset, emotion)\n","    image_files = random.sample(os.listdir(emotion_dir), 12)\n","\n","    # Construct the HTML string to display the images\n","    display_str = f'<div style=\"display:flex; flex-wrap: wrap;\">'\n","    for image_file in image_files:\n","        image_path = os.path.join(emotion_dir, image_file)\n","        with open(image_path, \"rb\") as img_file:\n","            img_data = base64.b64encode(img_file.read()).decode(\"ascii\")\n","            img_html = f'<img src=\"data:image/png;base64,{img_data}\" style=\"margin: 5px; width: 180px; height: auto;\"/>'\n","            display_str += img_html\n","\n","    display_str += '</div>'\n","    display(HTML(display_str))\n","\n","# Emotions and datasets\n","emotions = ['happy', 'sad', 'surprise', 'neutral']\n","datasets = ['train', 'validation', 'test']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OpGFI0MhE0Ey"},"outputs":[],"source":["# Show a random sampling from 'happy'\n","for dataset in datasets:\n","  display_random_images('happy', dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zg-N74bSE2XX"},"outputs":[],"source":["# Show a random sampling from 'sad'\n","for dataset in datasets:\n","  display_random_images('sad', dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U0KcfX21E4gK"},"outputs":[],"source":["# Show a random sampling from 'surprise'\n","for dataset in datasets:\n","  display_random_images('surprise', dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v5-VFWWfE6nZ"},"outputs":[],"source":["# Show a random sampling from 'neutral'\n","for dataset in datasets:\n","  display_random_images('neutral', dataset)"]},{"cell_type":"markdown","metadata":{"id":"NOshVMkHE-dN"},"source":["**Observations:**\n","\n","On the quality of the images:\n","- Some images have overlayed text or numbers e.g. shutterstock or other numbers\n","- There are some images that are not faces at all e.g. blank squares or missing images\n","- I don't necessarily agree with some of the provided labels, specifically between the 'sad' and 'neutral' categories\n","\n","On the diversity of the image faces:\n","- There is a variety of ages, ranging from less than 1 year to over 70 years old\n","- There is a variety of genders and skin tones\n","- There is a variety of hair styles / facial hair\n","- Some people are wearing glasses, sunglasses, hats, headsets, eyepatches\n","- There are some non-human cartoon/sketch faces\n","\n","On the diversity of facial arrangement and contrast:\n","- Some images are full face, others have different levels of zoom/cropping (predominantly chin or forehead cut off)\n","- Sometimes the face is straight aligned, sometimes angled\n","- Sometimes the face is camera facing, sometimes side profile\n","- There are varying degrees of contrast between the foreground and the background and choice of lighting\n","- Most of the time the image is just a face, but in some cases there are items in the background e.g. a laptop\n","\n","Some notable characteristics with respect to the defined classes:\n","- Happy: lots of teeth\n","- Sad: larger proportion of angled down faces, more frequently not camera facing\n","- Surprise: raised eyebrows, wide eyes, frequently hands on face, mouths open\n","- Neutral: difficult to identify"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":0}